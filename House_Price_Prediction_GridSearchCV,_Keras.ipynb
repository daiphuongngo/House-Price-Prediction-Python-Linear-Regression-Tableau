{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House Price Prediction - GridSearchCV, Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3LJHPmQ3Bau"
      },
      "source": [
        "# House Price Prediction - GridSearchCV, Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiXdnZ8olMii"
      },
      "source": [
        "# 1. Theory Review\n",
        "\n",
        "## 1.1 Search in Machine Learning\n",
        "\n",
        "What is the search issue in ML?\n",
        "\n",
        "- Search issue in ML is essentially optimizing ML model, i.e., finding the best model (or function) in the chosen model architecture (or function space) so that performance measure of the selected model on the training dataset (as well as test set) is highest.\n",
        "\n",
        "## 1.2 Gradient Vector\n",
        "\n",
        "What is the geometric intuition of gradient vector?\n",
        "\n",
        "- Gradient vector is the direction in parameter space with highest changing speed/rate of function output.\n",
        "\n",
        "## 1.3  Gradient Descent variants \n",
        "\n",
        "What are the main points to differentiate batch GD  vs. stochastic GD vs. Adam?\n",
        "\n",
        "- Batch GD: true gradient, computed for whole dataset, hence computationally expensive (bad for big training set) but provides fast convergence. Stochastic GD: a sample approximating the true gradient, computed on a single (random) input, hence computationally very cheap (good for big training set) but noisy update.  Adam: momentum + individual adaptive learning rate, hence usually a better method. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ocLL1JEj-Zv"
      },
      "source": [
        "# 2. Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdsbfsVSa846"
      },
      "source": [
        "## Orginal Dataset\n",
        "\n",
        "https://www.kaggle.com/shree1992/housedata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJW1CDAxYerJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0c0ed3a-abca-43d0-83a9-36da530e564e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG27TpReTO3J"
      },
      "source": [
        "In this project, I will use Deep Neural Network (DNN) for Regression method to predict house price based on data (size, bedrooms, ...)\n",
        "\n",
        "Dataset here is the **Ames Housing dataset** including 79 features and 1 label as the house price. However, in this project, dataset is narrowed down to only 10 features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OJ1A3iJ3W96"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qTryuFXZSx3"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1612)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(1612)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acenuZ25ZB9W"
      },
      "source": [
        "## Prepare the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQLanZLEa2Qq"
      },
      "source": [
        "### Read the CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WviujcCpxb3W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d33550c-5091-4dce-d45b-4a3c1925162e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "DATA_PATH = '/content/drive/My Drive/Colab Notebooks/AI Practitioner - 2020/Files/s6_houseprice.csv'\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print('Shape of dataframe:', df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of dataframe: (1462, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lSERI4Be5yz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "b80bfd3d-c95d-4bcc-b7c9-1d3bb5e9cc4b"
      },
      "source": [
        "df.head(10) #xem 10 dòng đầu tiên của dataframe "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8450.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>856.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>548.0</td>\n",
              "      <td>208500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9600.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1262.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>181500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11250.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>920.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>608.0</td>\n",
              "      <td>223500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9550.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>756.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>642.0</td>\n",
              "      <td>140000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14260.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1145.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>836.0</td>\n",
              "      <td>250000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>14115.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>796.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>143000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10084.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1686.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>636.0</td>\n",
              "      <td>307000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10382.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1107.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>484.0</td>\n",
              "      <td>200000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6120.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>952.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>468.0</td>\n",
              "      <td>129900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7420.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>991.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>118000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   LotArea  OverallQual  OverallCond  ...  Fireplaces  GarageArea  SalePrice\n",
              "0   8450.0          7.0          5.0  ...         0.0       548.0   208500.0\n",
              "1   9600.0          6.0          8.0  ...         1.0       460.0   181500.0\n",
              "2  11250.0          7.0          5.0  ...         1.0       608.0   223500.0\n",
              "3   9550.0          7.0          5.0  ...         1.0       642.0   140000.0\n",
              "4  14260.0          8.0          5.0  ...         1.0       836.0   250000.0\n",
              "5  14115.0          5.0          5.0  ...         0.0       480.0   143000.0\n",
              "6  10084.0          8.0          5.0  ...         1.0       636.0   307000.0\n",
              "7  10382.0          7.0          6.0  ...         2.0       484.0   200000.0\n",
              "8   6120.0          7.0          5.0  ...         2.0       468.0   129900.0\n",
              "9   7420.0          5.0          6.0  ...         2.0       205.0   118000.0\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1-WFAt7fQJB"
      },
      "source": [
        "### Check NULL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJHxvUbNbANS"
      },
      "source": [
        "Check if all columns has Null or NaN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQszsbu8ZP68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "f76667f9-42ef-4a6f-e7c6-c3b588a292da"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1462 entries, 0 to 1461\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   LotArea       1460 non-null   float64\n",
            " 1   OverallQual   1460 non-null   float64\n",
            " 2   OverallCond   1460 non-null   float64\n",
            " 3   TotalBsmtSF   1460 non-null   float64\n",
            " 4   FullBath      1460 non-null   float64\n",
            " 5   HalfBath      1460 non-null   float64\n",
            " 6   BedroomAbvGr  1460 non-null   float64\n",
            " 7   TotRmsAbvGrd  1460 non-null   float64\n",
            " 8   Fireplaces    1460 non-null   float64\n",
            " 9   GarageArea    1460 non-null   float64\n",
            " 10  SalePrice     1460 non-null   float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 125.8 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Q3HcDQeq6F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "6cb8d403-bddc-47db-fe2d-160da6113259"
      },
      "source": [
        "df.isna().sum() # check the number of null (na - Not available)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LotArea         2\n",
              "OverallQual     2\n",
              "OverallCond     2\n",
              "TotalBsmtSF     2\n",
              "FullBath        2\n",
              "HalfBath        2\n",
              "BedroomAbvGr    2\n",
              "TotRmsAbvGrd    2\n",
              "Fireplaces      2\n",
              "GarageArea      2\n",
              "SalePrice       2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz_iQGg6e-V8"
      },
      "source": [
        "Remove all null or NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99DBkL_ffIER"
      },
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xBefVB9fm7y"
      },
      "source": [
        "Check again if all Null or Nan values are gone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ATYl0ifmcE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "8463b638-615b-42a5-b564-a5a8fb02fb62"
      },
      "source": [
        "df.isna().sum() # check the number of null (na - Not available)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LotArea         0\n",
              "OverallQual     0\n",
              "OverallCond     0\n",
              "TotalBsmtSF     0\n",
              "FullBath        0\n",
              "HalfBath        0\n",
              "BedroomAbvGr    0\n",
              "TotRmsAbvGrd    0\n",
              "Fireplaces      0\n",
              "GarageArea      0\n",
              "SalePrice       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ8PQriSbeJF"
      },
      "source": [
        "### Statistical report of the dataset (Generate descriptive statistics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqcLf7zDbHe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "58af3068-635c-4595-8fcf-d4d85d169f14"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10516.828082</td>\n",
              "      <td>6.099315</td>\n",
              "      <td>5.575342</td>\n",
              "      <td>1057.429452</td>\n",
              "      <td>1.565068</td>\n",
              "      <td>0.382877</td>\n",
              "      <td>2.866438</td>\n",
              "      <td>6.517808</td>\n",
              "      <td>0.613014</td>\n",
              "      <td>472.980137</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9981.264932</td>\n",
              "      <td>1.382997</td>\n",
              "      <td>1.112799</td>\n",
              "      <td>438.705324</td>\n",
              "      <td>0.550916</td>\n",
              "      <td>0.502885</td>\n",
              "      <td>0.815778</td>\n",
              "      <td>1.625393</td>\n",
              "      <td>0.644666</td>\n",
              "      <td>213.804841</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7553.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>795.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>334.500000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9478.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>991.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>11601.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1298.250000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6110.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1418.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             LotArea  OverallQual  ...   GarageArea      SalePrice\n",
              "count    1460.000000  1460.000000  ...  1460.000000    1460.000000\n",
              "mean    10516.828082     6.099315  ...   472.980137  180921.195890\n",
              "std      9981.264932     1.382997  ...   213.804841   79442.502883\n",
              "min      1300.000000     1.000000  ...     0.000000   34900.000000\n",
              "25%      7553.500000     5.000000  ...   334.500000  129975.000000\n",
              "50%      9478.500000     6.000000  ...   480.000000  163000.000000\n",
              "75%     11601.500000     7.000000  ...   576.000000  214000.000000\n",
              "max    215245.000000    10.000000  ...  1418.000000  755000.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DFcwg-efZdx"
      },
      "source": [
        "## Split the dataset into Train and Test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_vXrWE-b1Vv"
      },
      "source": [
        "Split the dataset into X, y\n",
        "\n",
        "Since the dataset contains only numerical values, I will use the function `.values` to transform it into numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQEuRYkAblnW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "cef03560-c037-4b7c-e62f-b3efc2e01e9d"
      },
      "source": [
        "np_data = df.values\n",
        "print('np_data: ', np_data)\n",
        "print('np_data shape: ', np_data.shape)\n",
        "X = np_data[:, :10]\n",
        "print('X: ', X)\n",
        "y = np_data[:,-1]\n",
        "print('y: ', y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "np_data:  [[8.45000e+03 7.00000e+00 5.00000e+00 ... 0.00000e+00 5.48000e+02\n",
            "  2.08500e+05]\n",
            " [9.60000e+03 6.00000e+00 8.00000e+00 ... 1.00000e+00 4.60000e+02\n",
            "  1.81500e+05]\n",
            " [1.12500e+04 7.00000e+00 5.00000e+00 ... 1.00000e+00 6.08000e+02\n",
            "  2.23500e+05]\n",
            " ...\n",
            " [9.04200e+03 7.00000e+00 9.00000e+00 ... 2.00000e+00 2.52000e+02\n",
            "  2.66500e+05]\n",
            " [9.71700e+03 5.00000e+00 6.00000e+00 ... 0.00000e+00 2.40000e+02\n",
            "  1.42125e+05]\n",
            " [9.93700e+03 5.00000e+00 6.00000e+00 ... 0.00000e+00 2.76000e+02\n",
            "  1.47500e+05]]\n",
            "np_data shape:  (1460, 11)\n",
            "X:  [[8.450e+03 7.000e+00 5.000e+00 ... 8.000e+00 0.000e+00 5.480e+02]\n",
            " [9.600e+03 6.000e+00 8.000e+00 ... 6.000e+00 1.000e+00 4.600e+02]\n",
            " [1.125e+04 7.000e+00 5.000e+00 ... 6.000e+00 1.000e+00 6.080e+02]\n",
            " ...\n",
            " [9.042e+03 7.000e+00 9.000e+00 ... 9.000e+00 2.000e+00 2.520e+02]\n",
            " [9.717e+03 5.000e+00 6.000e+00 ... 5.000e+00 0.000e+00 2.400e+02]\n",
            " [9.937e+03 5.000e+00 6.000e+00 ... 6.000e+00 0.000e+00 2.760e+02]]\n",
            "y:  [208500. 181500. 223500. ... 266500. 142125. 147500.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgXKvPUQ4fZu"
      },
      "source": [
        "print('Shape of X:', X.shape)\n",
        "print('Shape of y:', y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX0wPA22f1Ck"
      },
      "source": [
        "Split the X, y dataset into Train, Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1X0ATMHeVdA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c61f7f74-1534-467a-914a-2cef161cdedb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=1612)   \n",
        "print('Shape of X train', X_train.shape)\n",
        "print('Shape of y train', y_train.shape)\n",
        "print('Shape of X test', X_test.shape)\n",
        "print('Shape of y test', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X train (1168, 10)\n",
            "Shape of y train (1168,)\n",
            "Shape of X test (292, 10)\n",
            "Shape of y test (292,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euWv4ccygXZo"
      },
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri035s10gmDf"
      },
      "source": [
        "As X, ybelongs to different ranges. in this project, I will apply Scaling to both X and y.\n",
        "\n",
        "Reference of Scaler types: [here](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02). So I can use any type of Scaler to apply to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxFWuvw0f_L7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "7cf0a891-e41a-4b5a-8433-841ca976d953"
      },
      "source": [
        "# 1. Choose any type of Scaler\n",
        "# 2. Create 2 Scale variables, name after x_scale and y_scale\n",
        "# 3. Proceed scaling on X_train, X_test and y_train, y_test\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)\n",
        "print('y_train shape: ', y_train.shape)\n",
        "print('y_test shape: ', y_test.shape)\n",
        "\n",
        "x_scale = StandardScaler()\n",
        "X_train_scaled = x_scale.fit_transform(X_train)\n",
        "X_test_scaled = x_scale.transform(X_test)\n",
        "print('X_train_scaled shape: ', X_train_scaled.shape)\n",
        "print('X_test_scaled shape: ', X_test_scaled.shape)\n",
        "\n",
        "y_scale = StandardScaler()\n",
        "y_train_scaled = y_scale.fit_transform(y_train)\n",
        "y_test_scaled = y_scale.transform(y_test)\n",
        "print('y_train_scaled shape: ', y_train_scaled.shape)\n",
        "print('y_test_scaled shape: ', y_test_scaled.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train shape:  (1168, 1)\n",
            "y_test shape:  (292, 1)\n",
            "X_train_scaled shape:  (1168, 10)\n",
            "X_test_scaled shape:  (292, 10)\n",
            "y_train_scaled shape:  (1168, 1)\n",
            "y_test_scaled shape:  (292, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO4sAtKvjE55"
      },
      "source": [
        "## Create a Deep Neural Network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdIFKZzfdxzL"
      },
      "source": [
        "## Keras review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6iqxLxTo2At"
      },
      "source": [
        "**Initialize optimizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OBNxAwzm7dx"
      },
      "source": [
        "Compile a model\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "model.compile(loss='', optimizer='adam', metrics=''\n",
        "```\n",
        "\n",
        "When compiling the model as above, optimizer will use the default learning rate of the system. To input the learning rate on my will, I will initialize the optimizer.\n",
        "\n",
        "```\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, ...\n",
        "\n",
        "my_optimizer = Adam(learning_rate = 0.01)\n",
        "# hoặc\n",
        "my_optimizer = SGD(learning_rate = 0.01, momentum = 0.9)\n",
        "# hoặc\n",
        "my_optimizer = RMSprop(learning_rate = 0.01, momentum = 0.9)\n",
        "\n",
        "model.compile(loss='', optimizer=my_optimizer, metrics='')\n",
        "```\n",
        "\n",
        "Some common learning_rate: 0.1 or 0.001 or 0.001.\n",
        "\n",
        "Som common mentum: 0.9 or 0.8.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdx9i4w3pUgb"
      },
      "source": [
        "**Khởi tạo model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y-nzkYfpW7T"
      },
      "source": [
        "There are 2 ways to initialize the model in Keras\n",
        "\n",
        "* Method 1: use Sequential\n",
        "\n",
        "```\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(16, activation='relu', input_shape=X.shape[1:]))\n",
        "...\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "```\n",
        "\n",
        "\n",
        "*   Method 2: use Model\n",
        "\n",
        "```\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "input = Input(shape=X.shape[1:])\n",
        "layer_1 = Dense(16, activation='relu')(input)\n",
        "layer_2 = Dense(16, activation='relu')(layer_1)\n",
        "layer_3 = Dense(16, activation='relu')(layer_2)\n",
        "output = Dense(1, activation='sigmoid')(layer_3)\n",
        "\n",
        "model=Model(input, output)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8dHTuCdo9oV"
      },
      "source": [
        "**Metrics for Regression**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FG4tk3cex_h"
      },
      "source": [
        "\n",
        "\n",
        "*  If it is a Regression case, output layer will have the following type\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "...\n",
        "model.add(Dense(1, activation='linear'))\n",
        "```\n",
        "\n",
        "*  Common metrics in the Regression include MAE, MSE, RMSE. To combine multiple metrics, I will code as follows:\n",
        "\n",
        "```\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "\n",
        "model.compile(loss='mse', optimizer='', metrics=['mae',RootMeanSquaredError()])\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Reference: RMSE vs MAE [here](https://thedatascientist.com/performance-measures-rmse-mae/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qfle-CvwxJc"
      },
      "source": [
        "**Plotting**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O9I9gSYe7qj"
      },
      "source": [
        "\n",
        "Plot after training the model\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "model.compile(loss='mse', optimizer='', metrics=['mae',RootMeanSquaredError()])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50)\n",
        "```\n",
        "\n",
        "Now, onkect history will save 3 metrics 'loss',  'mae'   'root_mean_squared_error' after 50 epochs\n",
        "\n",
        "To see those metrics, I will use the command\n",
        "\n",
        "```\n",
        "print(history.history.keys())\n",
        "```\n",
        "\n",
        "To plot a chart for loss after 50 epochs, I will use the command\n",
        "\n",
        "```\n",
        "plt.plot(history.history['loss']) # loss is one of metrics returned after calling the above function print()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju48JqJc_e1B"
      },
      "source": [
        "## Combine SkLearn's GridSearchCV with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv0gGF2OYrBE"
      },
      "source": [
        "**Note**\n",
        "\n",
        "The below code is for reference only. I will need to modify and combine the below code to my project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKZiZk7_rI8"
      },
      "source": [
        "To combine GridSearchCV from SkLearn with Keras, I will import these libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1irN0b3F_qvh"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# As this is a Regression cas, I will use KerasRegressor\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gJEW2TBAHoq"
      },
      "source": [
        "I will write a function create_model() to create a Keras model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfX3hbJDAB2k"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "\n",
        "def create_model(optimizer='adam', learning_rate=0.1, momentum=0.9):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, activation='relu', input_shape=X_train.shape[1:]))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(1, activation='linear'))\n",
        "  my_optim=None\n",
        "  if optimizer == 'adam':\n",
        "    # if optimizer is adam, there will be no learning_rate\n",
        "    my_optim = Adam(learning_rate=learning_rate)\n",
        "  elif optimizer == 'sgd':\n",
        "    my_optim = SGD(learning_rate=learning_rate, momentum=momentum)\n",
        "  elif optimizer == 'rmsprop':\n",
        "    my_optim = RMSprop(learning_rate=learning_rate, momentum=momentum)\n",
        "  \n",
        "  model.compile(loss='mse', optimizer=my_optim, metrics=['mae',RootMeanSquaredError()])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxPw-K0rDgdz"
      },
      "source": [
        "\n",
        "Next, I will create a dictionary containing metrics to be searched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_oK1N0uCVQV"
      },
      "source": [
        "# Define the grid search parameters\n",
        "optimizer_values = ['adam', 'sgd', 'rmsprop']\n",
        "lr_values = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "momentum_values = [0.0, 0.6, 0.8, 0.9]\n",
        "\n",
        "param_grid = {\n",
        "    'optimizer': optimizer_values,\n",
        "    'learning_rate': lr_values,\n",
        "    'momentum': momentum_values\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0ZzSez8Dosx"
      },
      "source": [
        "Initialize the model by KerasRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUUENx62Dm03"
      },
      "source": [
        "model = KerasRegressor(build_fn=create_model, epochs=80, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z344ldaNPCop"
      },
      "source": [
        "Create GridSearchCV and fit the model on X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVYgpXPrdpkf"
      },
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "print(\"Best model using: %s\" % (grid_result.best_params_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLUO1D2bXKBK"
      },
      "source": [
        "Get the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnLaZNOuQkJf"
      },
      "source": [
        "best_model = grid_result.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl6IQfeqaSRo"
      },
      "source": [
        "Evaluate the performance on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njXInz8macGY"
      },
      "source": [
        "best_model.model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw2jZ1zlJfzG"
      },
      "source": [
        "best_model.model.evaluate(X_test_scaled, y_test_scaled) # as it it scaled so I should use this command instead of the above one"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjvuussUeE4c"
      },
      "source": [
        "As I have used GridSearchCV, I will not be able to plot the loss function after epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwApIWUPtdlT"
      },
      "source": [
        "## Implement a Deep Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeYmBglk61Rr"
      },
      "source": [
        "I will now implement 1 Deep Neural Network (DNN) to sove the case of predicting house price\n",
        "\n",
        "### Goal\n",
        "\n",
        "* Use methods of scaling, optimizer, learning)rate, model architecture\n",
        "* **Apply GridSearchCV in Koeras to find the best optimizer, learning_rate, momentum**\n",
        "* **After training the model, I will evaluate the performance on Test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAZQIDttI434"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, Dropout, Flatten\n",
        "# Regression: use KerasRegressor\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYcPk33FK0Il"
      },
      "source": [
        "# ===========================================\n",
        "# Case 1: learning_rate=0.01, momentum=0.9\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_model(optimizer='sgd', learning_rate=0.01, momentum=0.9):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, activation='relu', input_shape=X_train.shape[1:]))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(1, activation='linear'))\n",
        "  # model.add(Dense(8, activation='relu', input_shape=X_train.shape[1:]))\n",
        "  # model.add(Dense(1, activation='linear'))\n",
        "  my_optim=None\n",
        "  if optimizer == 'adam':\n",
        "    # if using optimizer as adam, there will be no learning_rate\n",
        "    my_optim = Adam(learning_rate=learning_rate)\n",
        "  elif optimizer == 'sgd':\n",
        "    my_optim = SGD(learning_rate=learning_rate, momentum=momentum)\n",
        "  elif optimizer == 'rmsprop':\n",
        "    my_optim = RMSprop(learning_rate=learning_rate, momentum=momentum)\n",
        "  \n",
        "  model.compile(loss='mse', optimizer=my_optim, metrics=['mae',RootMeanSquaredError()])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMvNg3gtLAKX"
      },
      "source": [
        "# Define the grid search parameters\n",
        "optimizer_values = ['adam', 'sgd', 'rmsprop']\n",
        "lr_values = [0.01, 0.1]\n",
        "momentum_values = [0.0, 0.9]\n",
        "\n",
        "param_grid = {\n",
        "    'optimizer': optimizer_values,\n",
        "    'learning_rate': lr_values,\n",
        "    'momentum': momentum_values\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfMOWIZJLCLT"
      },
      "source": [
        "model = KerasRegressor(build_fn=create_model, epochs=80, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvZ99DGfLE8J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "85867364-010e-49ca-e184-a0bb4e35f1c2"
      },
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train_scaled, y_train_scaled)\n",
        "print(\"Best model using: %s\" % (grid_result.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.6865 - mae: 0.5725 - root_mean_squared_error: 0.8286\n",
            "Epoch 2/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.2810 - mae: 0.3369 - root_mean_squared_error: 0.5301\n",
            "Epoch 3/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.2364 - mae: 0.3034 - root_mean_squared_error: 0.4862\n",
            "Epoch 4/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.2248 - mae: 0.2896 - root_mean_squared_error: 0.4742\n",
            "Epoch 5/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.2095 - mae: 0.2798 - root_mean_squared_error: 0.4577\n",
            "Epoch 6/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1992 - mae: 0.2747 - root_mean_squared_error: 0.4463\n",
            "Epoch 7/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1849 - mae: 0.2675 - root_mean_squared_error: 0.4300\n",
            "Epoch 8/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1815 - mae: 0.2674 - root_mean_squared_error: 0.4260\n",
            "Epoch 9/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1757 - mae: 0.2617 - root_mean_squared_error: 0.4191\n",
            "Epoch 10/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1787 - mae: 0.2653 - root_mean_squared_error: 0.4228\n",
            "Epoch 11/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1683 - mae: 0.2592 - root_mean_squared_error: 0.4102\n",
            "Epoch 12/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1672 - mae: 0.2565 - root_mean_squared_error: 0.4089\n",
            "Epoch 13/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1621 - mae: 0.2544 - root_mean_squared_error: 0.4026\n",
            "Epoch 14/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1531 - mae: 0.2524 - root_mean_squared_error: 0.3913\n",
            "Epoch 15/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1485 - mae: 0.2488 - root_mean_squared_error: 0.3854\n",
            "Epoch 16/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1427 - mae: 0.2462 - root_mean_squared_error: 0.3777\n",
            "Epoch 17/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1438 - mae: 0.2446 - root_mean_squared_error: 0.3793\n",
            "Epoch 18/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1429 - mae: 0.2444 - root_mean_squared_error: 0.3780\n",
            "Epoch 19/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1390 - mae: 0.2451 - root_mean_squared_error: 0.3728\n",
            "Epoch 20/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1365 - mae: 0.2406 - root_mean_squared_error: 0.3695\n",
            "Epoch 21/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1321 - mae: 0.2386 - root_mean_squared_error: 0.3635\n",
            "Epoch 22/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1356 - mae: 0.2411 - root_mean_squared_error: 0.3682\n",
            "Epoch 23/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1294 - mae: 0.2401 - root_mean_squared_error: 0.3597\n",
            "Epoch 24/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1275 - mae: 0.2368 - root_mean_squared_error: 0.3571\n",
            "Epoch 25/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1229 - mae: 0.2350 - root_mean_squared_error: 0.3505\n",
            "Epoch 26/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1225 - mae: 0.2329 - root_mean_squared_error: 0.3500\n",
            "Epoch 27/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1221 - mae: 0.2350 - root_mean_squared_error: 0.3494\n",
            "Epoch 28/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1202 - mae: 0.2309 - root_mean_squared_error: 0.3466\n",
            "Epoch 29/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1202 - mae: 0.2310 - root_mean_squared_error: 0.3466\n",
            "Epoch 30/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1150 - mae: 0.2281 - root_mean_squared_error: 0.3392\n",
            "Epoch 31/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1153 - mae: 0.2280 - root_mean_squared_error: 0.3395\n",
            "Epoch 32/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1125 - mae: 0.2257 - root_mean_squared_error: 0.3354\n",
            "Epoch 33/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1099 - mae: 0.2240 - root_mean_squared_error: 0.3316\n",
            "Epoch 34/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1108 - mae: 0.2267 - root_mean_squared_error: 0.3329\n",
            "Epoch 35/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1122 - mae: 0.2260 - root_mean_squared_error: 0.3350\n",
            "Epoch 36/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1117 - mae: 0.2252 - root_mean_squared_error: 0.3343\n",
            "Epoch 37/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1126 - mae: 0.2258 - root_mean_squared_error: 0.3355\n",
            "Epoch 38/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1064 - mae: 0.2213 - root_mean_squared_error: 0.3261\n",
            "Epoch 39/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1070 - mae: 0.2225 - root_mean_squared_error: 0.3272\n",
            "Epoch 40/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1062 - mae: 0.2224 - root_mean_squared_error: 0.3259\n",
            "Epoch 41/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1041 - mae: 0.2178 - root_mean_squared_error: 0.3227\n",
            "Epoch 42/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1049 - mae: 0.2206 - root_mean_squared_error: 0.3239\n",
            "Epoch 43/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1022 - mae: 0.2183 - root_mean_squared_error: 0.3197\n",
            "Epoch 44/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1017 - mae: 0.2193 - root_mean_squared_error: 0.3190\n",
            "Epoch 45/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1035 - mae: 0.2188 - root_mean_squared_error: 0.3218\n",
            "Epoch 46/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1018 - mae: 0.2170 - root_mean_squared_error: 0.3191\n",
            "Epoch 47/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1008 - mae: 0.2155 - root_mean_squared_error: 0.3174\n",
            "Epoch 48/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1003 - mae: 0.2148 - root_mean_squared_error: 0.3167\n",
            "Epoch 49/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0988 - mae: 0.2145 - root_mean_squared_error: 0.3144\n",
            "Epoch 50/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0979 - mae: 0.2147 - root_mean_squared_error: 0.3130\n",
            "Epoch 51/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0971 - mae: 0.2142 - root_mean_squared_error: 0.3117\n",
            "Epoch 52/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0960 - mae: 0.2112 - root_mean_squared_error: 0.3099\n",
            "Epoch 53/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0975 - mae: 0.2138 - root_mean_squared_error: 0.3122\n",
            "Epoch 54/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0954 - mae: 0.2119 - root_mean_squared_error: 0.3089\n",
            "Epoch 55/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0947 - mae: 0.2129 - root_mean_squared_error: 0.3077\n",
            "Epoch 56/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0923 - mae: 0.2107 - root_mean_squared_error: 0.3039\n",
            "Epoch 57/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0956 - mae: 0.2112 - root_mean_squared_error: 0.3092\n",
            "Epoch 58/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0929 - mae: 0.2113 - root_mean_squared_error: 0.3047\n",
            "Epoch 59/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0907 - mae: 0.2070 - root_mean_squared_error: 0.3011\n",
            "Epoch 60/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0926 - mae: 0.2074 - root_mean_squared_error: 0.3043\n",
            "Epoch 61/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0899 - mae: 0.2072 - root_mean_squared_error: 0.2999\n",
            "Epoch 62/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0905 - mae: 0.2076 - root_mean_squared_error: 0.3008\n",
            "Epoch 63/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0904 - mae: 0.2074 - root_mean_squared_error: 0.3007\n",
            "Epoch 64/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0903 - mae: 0.2075 - root_mean_squared_error: 0.3005\n",
            "Epoch 65/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0883 - mae: 0.2060 - root_mean_squared_error: 0.2972\n",
            "Epoch 66/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0872 - mae: 0.2047 - root_mean_squared_error: 0.2953\n",
            "Epoch 67/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0865 - mae: 0.2032 - root_mean_squared_error: 0.2941\n",
            "Epoch 68/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0861 - mae: 0.2033 - root_mean_squared_error: 0.2935\n",
            "Epoch 69/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0855 - mae: 0.2017 - root_mean_squared_error: 0.2923\n",
            "Epoch 70/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0857 - mae: 0.2029 - root_mean_squared_error: 0.2927\n",
            "Epoch 71/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0834 - mae: 0.1999 - root_mean_squared_error: 0.2888\n",
            "Epoch 72/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0840 - mae: 0.2008 - root_mean_squared_error: 0.2898\n",
            "Epoch 73/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0823 - mae: 0.2001 - root_mean_squared_error: 0.2870\n",
            "Epoch 74/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0818 - mae: 0.2010 - root_mean_squared_error: 0.2859\n",
            "Epoch 75/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0827 - mae: 0.2004 - root_mean_squared_error: 0.2876\n",
            "Epoch 76/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0814 - mae: 0.1999 - root_mean_squared_error: 0.2854\n",
            "Epoch 77/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0825 - mae: 0.1987 - root_mean_squared_error: 0.2872\n",
            "Epoch 78/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0807 - mae: 0.1978 - root_mean_squared_error: 0.2841\n",
            "Epoch 79/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0818 - mae: 0.1983 - root_mean_squared_error: 0.2860\n",
            "Epoch 80/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0816 - mae: 0.1982 - root_mean_squared_error: 0.2857\n",
            "Best model using: {'learning_rate': 0.01, 'momentum': 0.0, 'optimizer': 'sgd'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mRlo2KrLKjj"
      },
      "source": [
        "best_model = grid_result.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C81uqy1aJv3t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "52cdd8f0-c076-45d7-a1b3-b80a65d28887"
      },
      "source": [
        "best_model.model.evaluate(X_test_scaled, y_test_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 1ms/step - loss: 0.1051 - mae: 0.2344 - root_mean_squared_error: 0.3241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1050662025809288, 0.23435331881046295, 0.32413917779922485]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uA_YC3S7_s9"
      },
      "source": [
        "## Compare MAE of y_test_scaled and y_pred_inverse\n",
        "\n",
        "Metrics are to evaluate the model performance but how much metrics should be depends on which I would like to define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM-VNS1QjkDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1967bf07-a839-4904-b55c-25fd5a71f4a5"
      },
      "source": [
        "y_pred = best_model.predict(X_test_scaled)\n",
        "y_pred_inverse = y_scale.inverse_transform(y_pred) # after scaling, I have to inverse_transform to see the real house price\n",
        "\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "mae = MeanAbsoluteError()\n",
        "print(mae(y_test_scaled, y_pred_inverse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 1ms/step\n",
            "tf.Tensor(186325.62, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYCsjVyL8-9A"
      },
      "source": [
        "## Compare RMSE of y_test_scaled and y_pred_inverse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAP5BfsPuyx6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0e51061-e9a8-4b48-cc98-ad65481ff765"
      },
      "source": [
        "from tensorflow.keras.metrics import MeanSquaredError\n",
        "import math\n",
        "mse = MeanSquaredError()\n",
        "print(math.sqrt(mse(y_test_scaled, y_pred_inverse)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200358.04878267305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cAE88yx9Eys"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTc3Yxk39JIi"
      },
      "source": [
        "The predicted MAE on the Test set is $186,325.62.\n",
        "\n",
        "The MAE on the scaled Test set is 0.2344.\n",
        "\n",
        "The real MAE is $184,885.94.\n",
        "\n",
        "As the Test set has 292 patterns, the MAE of them is $186,325.62 * 292 = $52,406,900.\n",
        "\n",
        "The RMSE of them is $200,358.05 * 292 = $58,504,536."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0TMeY6F-gmy"
      },
      "source": [
        "As I have used GridSearch to find the best model (optimizers, learning rate,...), I can not return its history plot. Only if I test the previous mode, I can plot the history then."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYs4eGKckjPx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cfc902d2-046a-4710-c020-1f386eeed83b"
      },
      "source": [
        "# Test the previous model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "import matplotlib.pyplot as plt\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "my_optim=SGD(learning_rate = 0.01, momentum = 0.0)\n",
        "model.compile(loss='mse', optimizer=my_optim, metrics=['mae',RootMeanSquaredError()])\n",
        "history = model.fit(X_train_scaled, y_train_scaled, epochs=80)\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['loss']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5246 - mae: 0.4610 - root_mean_squared_error: 0.7243\n",
            "Epoch 2/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.2562 - mae: 0.3084 - root_mean_squared_error: 0.5061\n",
            "Epoch 3/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2233 - mae: 0.2905 - root_mean_squared_error: 0.4725\n",
            "Epoch 4/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2130 - mae: 0.2813 - root_mean_squared_error: 0.4616\n",
            "Epoch 5/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1983 - mae: 0.2735 - root_mean_squared_error: 0.4453\n",
            "Epoch 6/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1881 - mae: 0.2697 - root_mean_squared_error: 0.4337\n",
            "Epoch 7/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1760 - mae: 0.2641 - root_mean_squared_error: 0.4195\n",
            "Epoch 8/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1723 - mae: 0.2630 - root_mean_squared_error: 0.4151\n",
            "Epoch 9/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1656 - mae: 0.2572 - root_mean_squared_error: 0.4069\n",
            "Epoch 10/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1678 - mae: 0.2599 - root_mean_squared_error: 0.4096\n",
            "Epoch 11/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1594 - mae: 0.2567 - root_mean_squared_error: 0.3993\n",
            "Epoch 12/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1573 - mae: 0.2539 - root_mean_squared_error: 0.3966\n",
            "Epoch 13/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1536 - mae: 0.2515 - root_mean_squared_error: 0.3919\n",
            "Epoch 14/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1449 - mae: 0.2494 - root_mean_squared_error: 0.3807\n",
            "Epoch 15/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1419 - mae: 0.2463 - root_mean_squared_error: 0.3767\n",
            "Epoch 16/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1348 - mae: 0.2425 - root_mean_squared_error: 0.3671\n",
            "Epoch 17/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1379 - mae: 0.2424 - root_mean_squared_error: 0.3714\n",
            "Epoch 18/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1369 - mae: 0.2405 - root_mean_squared_error: 0.3700\n",
            "Epoch 19/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1338 - mae: 0.2414 - root_mean_squared_error: 0.3657\n",
            "Epoch 20/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1320 - mae: 0.2381 - root_mean_squared_error: 0.3633\n",
            "Epoch 21/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1285 - mae: 0.2364 - root_mean_squared_error: 0.3585\n",
            "Epoch 22/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1320 - mae: 0.2387 - root_mean_squared_error: 0.3634\n",
            "Epoch 23/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1258 - mae: 0.2364 - root_mean_squared_error: 0.3547\n",
            "Epoch 24/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1246 - mae: 0.2343 - root_mean_squared_error: 0.3530\n",
            "Epoch 25/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1212 - mae: 0.2322 - root_mean_squared_error: 0.3481\n",
            "Epoch 26/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1198 - mae: 0.2298 - root_mean_squared_error: 0.3461\n",
            "Epoch 27/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1205 - mae: 0.2332 - root_mean_squared_error: 0.3471\n",
            "Epoch 28/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1177 - mae: 0.2273 - root_mean_squared_error: 0.3431\n",
            "Epoch 29/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1183 - mae: 0.2288 - root_mean_squared_error: 0.3439\n",
            "Epoch 30/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1138 - mae: 0.2252 - root_mean_squared_error: 0.3373\n",
            "Epoch 31/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1145 - mae: 0.2254 - root_mean_squared_error: 0.3383\n",
            "Epoch 32/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1109 - mae: 0.2246 - root_mean_squared_error: 0.3330\n",
            "Epoch 33/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1091 - mae: 0.2216 - root_mean_squared_error: 0.3304\n",
            "Epoch 34/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1094 - mae: 0.2239 - root_mean_squared_error: 0.3307\n",
            "Epoch 35/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1110 - mae: 0.2226 - root_mean_squared_error: 0.3332\n",
            "Epoch 36/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1108 - mae: 0.2231 - root_mean_squared_error: 0.3328\n",
            "Epoch 37/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1102 - mae: 0.2233 - root_mean_squared_error: 0.3320\n",
            "Epoch 38/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1045 - mae: 0.2186 - root_mean_squared_error: 0.3233\n",
            "Epoch 39/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1058 - mae: 0.2196 - root_mean_squared_error: 0.3253\n",
            "Epoch 40/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1042 - mae: 0.2188 - root_mean_squared_error: 0.3227\n",
            "Epoch 41/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1028 - mae: 0.2167 - root_mean_squared_error: 0.3206\n",
            "Epoch 42/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1030 - mae: 0.2185 - root_mean_squared_error: 0.3209\n",
            "Epoch 43/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1008 - mae: 0.2161 - root_mean_squared_error: 0.3175\n",
            "Epoch 44/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0998 - mae: 0.2161 - root_mean_squared_error: 0.3160\n",
            "Epoch 45/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1016 - mae: 0.2156 - root_mean_squared_error: 0.3187\n",
            "Epoch 46/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.1000 - mae: 0.2147 - root_mean_squared_error: 0.3162\n",
            "Epoch 47/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0992 - mae: 0.2134 - root_mean_squared_error: 0.3150\n",
            "Epoch 48/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0986 - mae: 0.2120 - root_mean_squared_error: 0.3140\n",
            "Epoch 49/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0969 - mae: 0.2119 - root_mean_squared_error: 0.3112\n",
            "Epoch 50/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0963 - mae: 0.2130 - root_mean_squared_error: 0.3103\n",
            "Epoch 51/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0953 - mae: 0.2116 - root_mean_squared_error: 0.3086\n",
            "Epoch 52/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0940 - mae: 0.2077 - root_mean_squared_error: 0.3066\n",
            "Epoch 53/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0952 - mae: 0.2111 - root_mean_squared_error: 0.3085\n",
            "Epoch 54/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0937 - mae: 0.2099 - root_mean_squared_error: 0.3062\n",
            "Epoch 55/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.2095 - root_mean_squared_error: 0.3044\n",
            "Epoch 56/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0910 - mae: 0.2080 - root_mean_squared_error: 0.3017\n",
            "Epoch 57/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0937 - mae: 0.2095 - root_mean_squared_error: 0.3061\n",
            "Epoch 58/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0906 - mae: 0.2075 - root_mean_squared_error: 0.3010\n",
            "Epoch 59/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0890 - mae: 0.2053 - root_mean_squared_error: 0.2984\n",
            "Epoch 60/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0908 - mae: 0.2053 - root_mean_squared_error: 0.3013\n",
            "Epoch 61/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0878 - mae: 0.2046 - root_mean_squared_error: 0.2963\n",
            "Epoch 62/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0883 - mae: 0.2043 - root_mean_squared_error: 0.2972\n",
            "Epoch 63/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0884 - mae: 0.2054 - root_mean_squared_error: 0.2973\n",
            "Epoch 64/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0880 - mae: 0.2050 - root_mean_squared_error: 0.2967\n",
            "Epoch 65/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0863 - mae: 0.2037 - root_mean_squared_error: 0.2938\n",
            "Epoch 66/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0855 - mae: 0.2030 - root_mean_squared_error: 0.2924\n",
            "Epoch 67/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0849 - mae: 0.2024 - root_mean_squared_error: 0.2913\n",
            "Epoch 68/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0843 - mae: 0.2003 - root_mean_squared_error: 0.2903\n",
            "Epoch 69/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0833 - mae: 0.1997 - root_mean_squared_error: 0.2886\n",
            "Epoch 70/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0835 - mae: 0.2009 - root_mean_squared_error: 0.2890\n",
            "Epoch 71/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0811 - mae: 0.1982 - root_mean_squared_error: 0.2848\n",
            "Epoch 72/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0822 - mae: 0.1986 - root_mean_squared_error: 0.2867\n",
            "Epoch 73/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0800 - mae: 0.1992 - root_mean_squared_error: 0.2828\n",
            "Epoch 74/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0798 - mae: 0.1976 - root_mean_squared_error: 0.2825\n",
            "Epoch 75/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0808 - mae: 0.1984 - root_mean_squared_error: 0.2842\n",
            "Epoch 76/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0793 - mae: 0.1983 - root_mean_squared_error: 0.2816\n",
            "Epoch 77/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0810 - mae: 0.1981 - root_mean_squared_error: 0.2847\n",
            "Epoch 78/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0794 - mae: 0.1953 - root_mean_squared_error: 0.2818\n",
            "Epoch 79/80\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0796 - mae: 0.1968 - root_mean_squared_error: 0.2821\n",
            "Epoch 80/80\n",
            "37/37 [==============================] - 0s 1ms/step - loss: 0.0801 - mae: 0.1975 - root_mean_squared_error: 0.2830\n",
            "dict_keys(['loss', 'mae', 'root_mean_squared_error'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efe29cc2860>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR0T9FHQt_Ps"
      },
      "source": [
        "As per the plot (x: epochs, y: loss), it has reached the max limit. Even if I keep training it, it will be quite the same for loss, mae and mse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG3HByjaN2ud",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4ad4d94-ab27-4072-8a96-bc3b3f97e581"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'mae', 'root_mean_squared_error'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUfa1ZXQRR-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f924b622-64f2-46a4-f964-223bd4bc2f78"
      },
      "source": [
        "# plt.plot(history.history['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efe29c55400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}